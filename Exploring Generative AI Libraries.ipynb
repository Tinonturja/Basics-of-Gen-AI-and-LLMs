{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b906c2-d8bf-4773-b3af-564df6989047",
   "metadata": {},
   "source": [
    "Model tyes we are going to cover is:\n",
    "1. RNN\n",
    "2. GAN\n",
    "3. Transformers\n",
    "4. Diffusion models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9aa321-686d-44bd-9152-24acbe1a4aaf",
   "metadata": {},
   "source": [
    "Text generation before transformers:\n",
    "    \n",
    "    1. N-gram models : works like a detective, predict what word comes after based on the word that comes before\n",
    "    \n",
    "    2. RNN : handle sequential data, making them a powerful tool for applications like language modeling and time series forecasting. The essence of their design lies in maintaing a `memory` or `hidden state`.\n",
    "    \n",
    "    3. LSTM and GRUs are advanced variations of recurrent neural networks, designed to adress the limitations of traditional RNNs and enhance their ability to model sequential data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ddd079-bec3-4841-9ed3-0d3a33c5de0f",
   "metadata": {},
   "source": [
    "### 4. Seq2seq models with attention\n",
    "- Sequence-to-sequence (seq2seq) models, often built with RNNs or LSTMs, were designed to handle tasks like translation where an input sequence is transformed into an output sequence.\n",
    "- The attention mechanism was introduced to allow the model to \"focus\" on relevant parts of the input sequence when generating the output, significantly improving performance on tasks like machine translation.\n",
    "\n",
    "While these methods provided significant advancements in text generation tasks, the introduction of transformers led to a paradigm shift. Transformers, with their self-attention mechanism, proved to be highly efficient at capturing contextual information across long sequences, setting new benchmarks in various NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2d44f-5407-4221-b515-567cd56331a2",
   "metadata": {},
   "source": [
    "## Building a simple chatbot with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d94d91b-9934-4aff-9694-7402a4187b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.42.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (4.42.1)\n",
      "Requirement already satisfied: filelock in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (0.30.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (2024.8.30)\n",
      "Requirement already satisfied: sentencepiece in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.2.2) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: torchtext==0.17.2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (4.65.0)\n",
      "Requirement already satisfied: requests in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (1.23.5)\n",
      "Requirement already satisfied: filelock in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (2025.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n",
      "zsh:1: =1.26 not found\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq tensorflow\n",
    "!pip install transformers==4.42.1 -U\n",
    "!pip install sentencepiece\n",
    "!pip install torch==2.2.2\n",
    "!pip install torchtext==0.17.2\n",
    "!pip install numpy ==1.26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc48fa5-497e-4b99-8740-de21a510c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
    "\n",
    "# Selecting the model, we are going to use \"facebook/blenderbot-40M-distill\" in this example\n",
    "\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08c539f-db59-4bd9-a204-e5259b8f6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_bot():\n",
    "    while True:\n",
    "\n",
    "        # Get user input\n",
    "        input_text = input(\"You: \")\n",
    "    \n",
    "        # Exit Conditions\n",
    "    \n",
    "        if input_text.lower() in ['quit','exit','bye']:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "    \n",
    "        # Tokenize input and generate response\n",
    "    \n",
    "        inputs = tokenizer.encode(input_text,return_tensors = 'pt')\n",
    "        outputs = model.generate(inputs, max_new_tokens = 150)\n",
    "        response = tokenizer.decode(outputs[0],skip_special_tokens = True).strip()\n",
    "\n",
    "        \n",
    "        # Display bot's response\n",
    "        print(\"Chatbot:\",response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4907552-50a9-460b-8c75-6255d7ded2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! How are you? I just got back from walking my dog. Do you have any pets?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I am fine. how about you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: I am doing well, thank you. I am glad to hear that you are doing well.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Start chatting\n",
    "chat_with_bot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140b245-7044-49c0-841e-7c7ccfcfe197",
   "metadata": {},
   "source": [
    "## Try another model and comparing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed0795d-ff80-4173-a7b9-18a96216b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_name = \"google/flan-t5-base\"\n",
    "\n",
    "model_2 = AutoModelForSeq2SeqLM.from_pretrained(model_2_name)\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_2_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e182342-3068-4e4c-9887-28a7c7afc096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  i'm a sailor and i'm a sailor. i'm a sailor and i'm a sailor.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what are you trying to say?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  The symphony orchestra is a great orchestra.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  are you mad?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  are you mad?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Chat with this bot\n",
    "def chat_with_another_bot():\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        input_text = input(\"You: \")\n",
    "\n",
    "\n",
    "        # Exit Conditions\n",
    "\n",
    "        if input_text.lower() in ['quit',\n",
    "                                 'exit',\n",
    "                                 'bye']:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokeninze input and generate response\n",
    "        \n",
    "        inputs = tokenizer_2.encode(input_text,return_tensors = 'pt')\n",
    "        outputs = model_2.generate(inputs,max_new_tokens =150)\n",
    "        response = tokenizer_2.decode(outputs[0],skip_special_tokens = True).strip()\n",
    "\n",
    "        # Display bot's response\n",
    "        print(\"Chatbot: \",response)\n",
    "\n",
    "\n",
    "# Start Chatting\n",
    "chat_with_another_bot()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8d3677-e00e-44af-b564-c3f9213313c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Chatbot\n",
    "model = \"facebook/bart-base\"\n",
    "\n",
    "model_3 = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323f4384-daf8-41af-883b-1f008d826f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  tell me about you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  tell me about you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!!\n"
     ]
    }
   ],
   "source": [
    "# Chat with final bot\n",
    "def chat_with_final_bot():\n",
    "\n",
    "    while True:\n",
    "        input_text = input(\"You: \")\n",
    "\n",
    "        if input_text.lower() in ['quit',\n",
    "                                 'bye',\n",
    "                                 'exit']:\n",
    "            print(\"Chatbot: Goodbye!!\")\n",
    "            break\n",
    "            \n",
    "\n",
    "        # Tokenize input and generate responses\n",
    "        inputs = tokenizer_3.encode(input_text,return_tensors='pt')\n",
    "        outputs = model_3.generate(inputs,max_new_tokens = 150)\n",
    "        response = tokenizer_3.decode(outputs[0],skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display Bot's response\n",
    "        print(\"Chatbot: \",response)\n",
    "\n",
    "# Start Chatting\n",
    "chat_with_final_bot()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a185a1-2e48-452d-a7db-c07bd3455a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
