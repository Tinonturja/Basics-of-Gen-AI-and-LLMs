{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b906c2-d8bf-4773-b3af-564df6989047",
   "metadata": {},
   "source": [
    "Model tyes we are going to cover is:\n",
    "1. RNN\n",
    "2. GAN\n",
    "3. Transformers\n",
    "4. Diffusion models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9aa321-686d-44bd-9152-24acbe1a4aaf",
   "metadata": {},
   "source": [
    "Text generation before transformers:\n",
    "    \n",
    "    1. N-gram models : works like a detective, predict what word comes after based on the word that comes before\n",
    "    \n",
    "    2. RNN : handle sequential data, making them a powerful tool for applications like language modeling and time series forecasting. The essence of their design lies in maintaing a `memory` or `hidden state`.\n",
    "    \n",
    "    3. LSTM and GRUs are advanced variations of recurrent neural networks, designed to adress the limitations of traditional RNNs and enhance their ability to model sequential data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ddd079-bec3-4841-9ed3-0d3a33c5de0f",
   "metadata": {},
   "source": [
    "### 4. Seq2seq models with attention\n",
    "- Sequence-to-sequence (seq2seq) models, often built with RNNs or LSTMs, were designed to handle tasks like translation where an input sequence is transformed into an output sequence.\n",
    "- The attention mechanism was introduced to allow the model to \"focus\" on relevant parts of the input sequence when generating the output, significantly improving performance on tasks like machine translation.\n",
    "\n",
    "While these methods provided significant advancements in text generation tasks, the introduction of transformers led to a paradigm shift. Transformers, with their self-attention mechanism, proved to be highly efficient at capturing contextual information across long sequences, setting new benchmarks in various NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2d44f-5407-4221-b515-567cd56331a2",
   "metadata": {},
   "source": [
    "## Building a simple chatbot with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d94d91b-9934-4aff-9694-7402a4187b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.15 requires protobuf<5,>=4.25.3, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting transformers==4.42.1\n",
      "  Obtaining dependency information for transformers==4.42.1 from https://files.pythonhosted.org/packages/32/a5/ad96309b47ede58104e109689819e24749c7b5bb1d935257240dbefe28dd/transformers-4.42.1-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.42.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.42.1)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.23.2 from https://files.pythonhosted.org/packages/93/27/1fb384a841e9661faad1c31cbfa62864f59632e876df5d795234da51c395/huggingface_hub-0.30.2-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.42.1)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/90/79/d17a0f491d10817cd30f1121a07aa09c8e97a81114b116e473baf1577f09/tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.42.1)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/b8/3b/11f1b4a2f5d2ab7da34ecc062b0bc301f2be024d110a6466726bec8c055c/safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from transformers==4.42.1) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/44/4b/e0cfc1a6f17e990f3e64b7d941ddc4acdc7b19d6edd51abf495f32b1a9e4/fsspec-2025.3.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.42.1) (2024.8.30)\n",
      "Downloading transformers-4.42.1-py3-none-any.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.2\n",
      "    Uninstalling safetensors-0.3.2:\n",
      "      Successfully uninstalled safetensors-0.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.1\n",
      "    Uninstalling transformers-4.32.1:\n",
      "      Successfully uninstalled transformers-4.32.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2025.3.2 huggingface-hub-0.30.2 safetensors-0.5.3 tokenizers-0.19.1 transformers-4.42.1\n",
      "Collecting sentencepiece\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/de/42/ae30952c4a0bd773e90c9bf2579f5533037c886dfc8ec68133d5694f4dd2/sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Collecting torch==2.2.2\n",
      "  Obtaining dependency information for torch==2.2.2 from https://files.pythonhosted.org/packages/96/23/18b9c16c18a77755e7f15173821c7100f11e6b3b7717bea8d729bdeb92c0/torch-2.2.2-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.2.2) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Downloading torch-2.2.2-cp311-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.20.1 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.2.2\n",
      "Collecting torchtext==0.17.2\n",
      "  Obtaining dependency information for torchtext==0.17.2 from https://files.pythonhosted.org/packages/c7/0a/3af1e9d2577a5a63b32122c7224223f958d10b6e21c557190c0747478ff3/torchtext-0.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchtext-0.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tqdm in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (4.65.0)\n",
      "Requirement already satisfied: requests in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torchtext==0.17.2) (1.23.5)\n",
      "Requirement already satisfied: filelock in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from torch==2.2.2->torchtext==0.17.2) (2025.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.17.2) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tinonturjamajumder/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n",
      "Downloading torchtext-0.17.2-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: torchtext\n",
      "Successfully installed torchtext-0.17.2\n",
      "zsh:1: =1.26 not found\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq tensorflow\n",
    "!pip install transformers==4.42.1 -U\n",
    "!pip install sentencepiece\n",
    "!pip install torch==2.2.2\n",
    "!pip install torchtext==0.17.2\n",
    "!pip install numpy ==1.26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc48fa5-497e-4b99-8740-de21a510c73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d0b3e7dc584026bbbf0055ffbbf1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4579d68676504a62bf814cf8a6405201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/730M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89f8894feac421bad658b7726b06c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305a2e676b3f4afeb8ae424cc922e964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35af5b9213434dd28744a250896f1355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf675efec4c4ba2a5c8da994034e2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/62.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca4673392b24a0ba2812b5f551a6570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b7e65cd2f04020a35c098b489eaafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f99c2de91be4bb296a04be8743303bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/310k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
    "\n",
    "# Selecting the model, we are going to use \"facebook/blenderbot-40M-distill\" in this example\n",
    "\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08c539f-db59-4bd9-a204-e5259b8f6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_bot():\n",
    "    while True:\n",
    "\n",
    "        # Get user input\n",
    "        input_text = input(\"You: \")\n",
    "    \n",
    "        # Exit Conditions\n",
    "    \n",
    "        if input_text.lower() in ['quit','exit','bye']:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "    \n",
    "        # Tokenize input and generate response\n",
    "    \n",
    "        inputs = tokenizer.encode(input_text,return_tensors = 'pt')\n",
    "        outputs = model.generate(inputs, max_new_tokens = 150)\n",
    "        response = tokenizer.decode(outputs[0],skip_special_tokens = True).strip()\n",
    "\n",
    "        \n",
    "        # Display bot's response\n",
    "        print(\"Chatbot:\",response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4907552-50a9-460b-8c75-6255d7ded2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi there\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! How are you? I just got back from walking my dog. Do you have any pets?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  No. I don't. How was your day?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: It was pretty good. I was able to get a lot of work done. How about yours?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Not that good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: I know, I feel so bad for him. I hope he can get the help he needs.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Start chatting\n",
    "chat_with_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0795d-ff80-4173-a7b9-18a96216b18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
